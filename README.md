# Direct Marketing Optimization

This repository contains a case study project for optimizing direct marketing campaigns in a banking context. Dummy customer data is used to predict purchase propensity and expected revenue for three products (Consumer Loan, Credit Card, Mutual Fund). An optimization step then selects which clients to contact in order to maximize total revenue while respecting contact limitations.

## Directory Overview

```
.
â”œâ”€â”€ .dockerignore         # Docker ignore file
â”œâ”€â”€ .env_example          # Environment variables template
â”œâ”€â”€ .gitignore            # Git ignore file
â”œâ”€â”€ README.md             # Project documentation
â”œâ”€â”€ artifacts/            # Generated artifacts
â”œâ”€â”€ conf/                 # Hydra configuration files
â”‚   â”œâ”€â”€ config.yaml       # Main configuration file
â”‚   â”œâ”€â”€ logging.yaml      # Logging configuration
â”‚   â”œâ”€â”€ propensity_model/ # Propensity model configurations
â”‚   â””â”€â”€ revenue_model/    # Revenue model configurations
â”œâ”€â”€ data/                 # Input data (raw/processed)
â”œâ”€â”€ docker/               # Docker configuration
â”‚   â””â”€â”€ direct-marketing.Dockerfile
â”œâ”€â”€ docker-compose.yml    # Compose file to run MLflow and the app
â”œâ”€â”€ docs/                 # Additional documentation
â”œâ”€â”€ images/               # Documentation images
â”œâ”€â”€ main.py               # Entry point for the workflow
â”œâ”€â”€ mlruns/               # MLflow experiment tracking data
â”œâ”€â”€ notebooks/            # Exploratory Jupyter notebooks
â”œâ”€â”€ outputs/              # Generated output files
â”œâ”€â”€ pages/                # Streamlit app pages
â”œâ”€â”€ pyproject.toml        # Python project configuration
â”œâ”€â”€ ruff.toml             # Ruff linter configuration
â”œâ”€â”€ src/                  # Source code package
â”œâ”€â”€ streamlit_app.py      # Main Streamlit application
â”œâ”€â”€ tests/                # Unit tests
â””â”€â”€ uv.lock               # UV dependency lock file
```

## Tech Stack

This project leverages several modern Python libraries and tools:

<div style="display: flex; justify-content: space-around; flex-wrap: wrap; align-items: center; margin-bottom: 20px;">
  <img src="images/hydra.png" alt="Hydra" height="30" style="margin: 2px;" />
  <img src="images/mlflow.webp" alt="MLflow" height="30" style="margin: 2px;" />
  <img src="images/optuna.jpg" alt="Optuna" height="30" style="margin: 2px;" />
  <img src="images/pydantic.jpg" alt="Pydantic" height="30" style="margin: 2px;" />
  <img src="images/pytest.svg" alt="PyTest" height="30" style="margin: 2px;" />
  <img src="images/sklearn.png" alt="Scikit-learn" height="30" style="margin: 2px;" />
  <img src="images/streamlit.png" alt="Streamlit" height="30" style="margin: 2px;" />
  <img src="images/ruff.png" alt="Ruff" height="30" style="margin: 2px;" />
  <img src="images/docker.png" alt="Docker" height="30" style="margin: 2px;" />
  <img src="images/plotly.png" alt="Plotly" height="30" style="margin: 2px;" />
</div>

- **Hydra** â€“ organizes configuration files and allows easy experiment
  management.
- **Optuna** â€“ performs hyperparameter search to find the best model settings.
- **MLflow** â€“ tracks experiments and stores models for later comparison.
- **Scikit-learn** â€“ provides machine learning algorithms used for training.
- **Streamlit** â€“ powers the simple web interface for exploring results.
- **Docker** â€“ containerizes the application and supporting services.
- **uv** â€“ handles dependency management and running Python scripts.
- **Ruff** â€“ enforces code style and static analysis checks.
- **Pytest** â€“ runs the unit test suite.
- **Pydantic** â€“ validates configuration and data schemas.
- **Plotly** â€“ provides visualizations.
- **CVXPY** â€“ optimization library for mathematical programming.
- **Streamlit** â€“ creates interactive multi-page web applications. 


## Architecture Overview

```mermaid
graph TD
    A[Hydra Config] --> B[DataLoader]
    B --> C[Preprocessor]
    C --> D1[Propensity Trainer]
    C --> D2[Revenue Trainer]
    D1 --> E1[Propensity Model]
    D2 --> E2[Revenue Model]
    E1 --> F[Inference]
    E2 --> F
    F --> G[Optimizer]
    G --> H[Evaluator]
    H --> I[Offer List]
    D1 --> J[MLflow Tracking]
    D2 --> J
```

## Diagram Step Descriptions

The flowchart outlines the key components of the marketing pipeline. Each node plays a specific role:

1. **Hydra Config** â€“ manages paths, parameters and overall configuration.
2. **DataLoader** â€“ reads raw files and converts them into data frames.
3. **Preprocessor** â€“ cleans, merges and engineers features for modeling.
4. **Propensity Trainer** â€“ fits a model predicting purchase likelihood.
5. **Revenue Trainer** â€“ fits a model estimating expected revenue.
6. **Propensity Model** â€“ saved model used to score new customers.
7. **Revenue Model** â€“ saved model used to forecast revenue for each offer.
8. **Inference** â€“ generates propensity scores and revenue predictions.
9. **Optimizer** â€“ selects the best customer-product pairs under contact limits.
10. **Evaluator** â€“ computes metrics like AUC and expected revenue.
11. **Offer List** â€“ final list of recommended offers per customer.
12. **MLflow Tracking** â€“ records experiments, metrics and artifacts.


## Configuration

Hydra configuration files live under `conf/`. The main file `conf/config.yaml` controls data paths, preprocessing settings, model training options and optimization parameters. Key fields include:

- `data.raw_excel_path` â€“ location of the Excel dataset.
- `products` â€“ list of products to model (`CL`, `MF`, `CC`).
- `optimization.contact_limit` â€“ maximum number of clients to contact.
- `mlflow` â€“ settings for experiment tracking.

Model-specific parameters are defined in `conf/propensity_model/` and `conf/revenue_model/`. Adjust these YAML files to change hyperparameters or the underlying algorithm.

## Running the Project

1. **Install dependencies**
   ```bash
   uv sync
   ```
2. **Run tests**
   ```bash
   PYTHONPATH=. pytest
   ```
3. **Execute the workflow**
   ```bash
   uv run main.py
   ```
4. **Launch the Streamlit dashboard**
   ```bash
   uv run streamlit run streamlit_app.py
   ```

### Docker Compose

To start an MLflow server and run the application in containers:

```bash
sudo docker compose -f docker-compose.yml up
```

This will build the application image and launch multiple services:
- `mlflow` for experiment tracking (accessible at http://localhost:5000)
- `direct-marketing` which runs the main pipeline
- `streamlit` which exposes the dashboard on port 8501

## Streamlit Application

The project includes a comprehensive Streamlit web application with multiple pages:

- **Methodology** â€“ explains the approach and methodology
- **Summary** â€“ provides an overview of results
- **Filter** â€“ allows filtering and exploration of data
- **Propensity** â€“ shows propensity model results and predictions
- **Evaluation** â€“ displays model evaluation metrics
- **Client List** â€“ presents the optimized client list for marketing
- **Revenue** â€“ shows revenue model predictions and analysis

Launch the app with:
```bash
uv run streamlit run streamlit_app.py
```

## Purpose

The goal is to maximize marketing revenue by:
1. Building propensity models for each product.
2. Estimating expected revenue from purchases.
3. Optimizing the targeting strategy so that each client receives at most one offer and the total number of contacts does not exceed the specified limit.

This setup mirrors a real-world scenario where a bank must allocate limited marketing resources to the most promising customers.

## Key Features

- **Multi-Product Modeling** â€“ supports modeling for Credit Cards (CC), Consumer Loans (CL), and Mutual Funds (MF)
- **Dual Model Architecture** â€“ separate models for purchase propensity and expected revenue
- **Hyperparameter Optimization** â€“ uses Optuna for automated hyperparameter tuning
- **Experiment Tracking** â€“ MLflow integration for model versioning and comparison
- **Interactive Dashboard** â€“ comprehensive Streamlit web interface
- **Optimization Engine** â€“ mathematical optimization to maximize revenue under constraints
- **Configurable Pipeline** â€“ Hydra-based configuration management
- **Comprehensive Testing** â€“ full test suite with pytest
- **Containerized Deployment** â€“ Docker support for easy deployment


## Dependencies

The project uses modern Python tooling and libraries as defined in `pyproject.toml`:

**Core ML/Data Libraries:**
- `scikit-learn` â€“ machine learning algorithms
- `pandas` & `numpy` â€“ data manipulation and analysis
- `cvxpy` â€“ convex optimization
- `mlflow` â€“ experiment tracking and model management

**Configuration & Workflow:**
- `hydra-core` â€“ configuration management
- `hydra-optuna-sweeper` â€“ hyperparameter optimization
- `pydantic` â€“ data validation and settings management

**Visualization & UI:**
- `streamlit` â€“ web application framework
- `plotly` â€“ interactive visualizations
- `matplotlib` & `seaborn` â€“ statistical plotting

**Development & Testing:**
- `pytest` â€“ testing framework
- `ruff` â€“ fast Python linter and formatter
- `jupyter` â€“ notebook environment

## Documentation

Project documentation is built with [Sphinx](https://www.sphinx-doc.org/). To
generate the HTML docs run:

```bash
cd docs
make html
```

The output will be available in `docs/build/html/index.html`.

## Author & Contact Information ðŸ‘‹

ðŸ‘¤ **Author:** Christopher Hoo

ðŸ“§ **Email:** c-hi.yang@hotmail.sg

ðŸ’¼ **LinkedIn:** [Link ðŸ”—](https://www.linkedin.com/in/christopher-chi-yang-hoo-570698bb/)
